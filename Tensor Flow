import time
import matplotlib.pyplot as plt
import numpy as np
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf

# Load and preprocess the data
data = load_diabetes()
X, y = data.data, data.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Convert data to TensorFlow datasets
def create_tf_dataset(X, y, batch_size=32):
    return tf.data.Dataset.from_tensor_slices((X, y)).shuffle(buffer_size=1000).batch(batch_size)

# Results dictionary
results = {}

# Define a simple regression model
def build_model(input_dim):
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(input_dim,)),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

# 1. Scalability with Data Size
def tensorflow_scalability_experiment():
    dataset_sizes = [int(len(X_train) * p) for p in [0.2, 0.4, 0.6, 0.8, 1.0]]
    training_times = []

    for size in dataset_sizes:
        X_sample, y_sample = X_train[:size], y_train[:size]
        train_dataset = create_tf_dataset(X_sample, y_sample)

        model = build_model(X_train.shape[1])

        start_time = time.time()
        model.fit(train_dataset, epochs=10, verbose=0)  # Train for 10 epochs
        training_times.append(time.time() - start_time)

    plt.figure()
    plt.plot([p * 100 for p in [0.2, 0.4, 0.6, 0.8, 1.0]], training_times, label="Training Time")
    plt.xlabel("Dataset Size (%)")
    plt.ylabel("Training Time (seconds)")
    plt.title("Scalability with Data Size - TensorFlow")
    plt.legend()
    plt.show()

    results['Scalability'] = training_times

# 2. Fault Tolerance
def tensorflow_fault_tolerance_experiment():
    try:
        X_sample, y_sample = X_train[:int(len(X_train) * 0.8)], y_train[:int(len(y_train) * 0.8)]
        train_dataset = create_tf_dataset(X_sample, y_sample)

        model = build_model(X_train.shape[1])

        start_time = time.time()
        model.fit(train_dataset, epochs=10, verbose=0)
        elapsed_time = time.time() - start_time

        plt.figure()
        plt.bar(["Training with Fault"], [elapsed_time], color='orange', label="Time with Fault")
        plt.ylabel("Training Time (seconds)")
        plt.title("Fault Tolerance - TensorFlow")
        plt.legend()
        plt.show()

        results['Fault Tolerance'] = elapsed_time
    except Exception as e:
        print("Simulation of fault failed:", e)

# 3. Communication Overhead
def tensorflow_communication_overhead_experiment():
    train_dataset = create_tf_dataset(X_train, y_train)

    model = build_model(X_train.shape[1])

    # Measure synchronous training
    start_time = time.time()
    model.fit(train_dataset, epochs=10, verbose=0)
    sync_time = time.time() - start_time

    # Simulate asynchronous training (not directly supported in TensorFlow, treated the same for simplicity)
    start_time = time.time()
    model.fit(train_dataset, epochs=10, verbose=0)
    async_time = time.time() - start_time

    plt.figure()
    plt.bar(["Synchronous", "Asynchronous"], [sync_time, async_time], color=['blue', 'green'])
    plt.ylabel("Training Time (seconds)")
    plt.title("Communication Overhead - TensorFlow")
    plt.show()

    results['Communication'] = {'Synchronous': sync_time, 'Asynchronous': async_time}

# 4. Ease of Use and Setup
def tensorflow_ease_of_use_experiment():
    start_time = time.time()

    # Simulate environment setup
    tf.keras.backend.clear_session()  # Reset TensorFlow session
    elapsed_time = time.time() - start_time

    plt.figure()
    plt.bar(["Environment Setup"], [elapsed_time], color='purple', label="Setup Time")
    plt.ylabel("Setup Time (seconds)")
    plt.title("Ease of Setup - TensorFlow")
    plt.legend()
    plt.show()

    results['Ease of Setup'] = elapsed_time

# General Graph for TensorFlow
def general_tensorflow_graph():
    aspects = ['Scalability', 'Fault Tolerance', 'Communication (Sync)', 'Communication (Async)', 'Ease of Setup']
    values = [
        sum(results['Scalability']) if 'Scalability' in results else 0,
        results['Fault Tolerance'] if 'Fault Tolerance' in results else 0,
        results['Communication']['Synchronous'] if 'Communication' in results else 0,
        results['Communication']['Asynchronous'] if 'Communication' in results else 0,
        results['Ease of Setup'] if 'Ease of Setup' in results else 0
    ]

    plt.figure()
    plt.bar(aspects, values, color=['red', 'orange', 'blue', 'green', 'purple'])
    plt.ylabel("Time/Performance (seconds)")
    plt.title("TensorFlow - General Framework Overview")
    plt.xticks(rotation=45)
    plt.show()

# Run all experiments
tensorflow_scalability_experiment()
tensorflow_fault_tolerance_experiment()
tensorflow_communication_overhead_experiment()
tensorflow_ease_of_use_experiment()
general_tensorflow_graph()

# Print results
print("Results Summary:")
for key, value in results.items():
    print(f"{key}: {value}")
